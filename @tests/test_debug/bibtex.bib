 @article{Zhu_2025, title={BERT and Its Applications in Natural Language Understanding}, volume={175}, ISSN={2755-273X}, url={http://dx.doi.org/10.54254/2755-2721/2025.ast26090}, DOI={10.54254/2755-2721/2025.ast26090}, number={1}, journal={Applied and Computational Engineering}, publisher={EWA Publishing}, author={Zhu, Ziting}, year={2025}, month=aug, pages={99â105} }

 @article{Priyanka_Yadav_2024, title={LEBERT:Lite and Efficiently Optimized BERT PRetraining Approach}, ISSN={2581-9429}, url={http://dx.doi.org/10.48175/ijarsct-15219}, DOI={10.48175/ijarsct-15219}, journal={International Journal of Advanced Research in Science, Communication and Technology}, publisher={Naksh Solutions}, author={Priyanka Yadav and Anjali Sharma}, year={2024}, month=jan, pages={110114} }

 @inproceedings{Jawahar_2019, title={What Does BERT Learn about the Structure of Language?}, url={http://dx.doi.org/10.18653/v1/p19-1356}, DOI={10.18653/v1/p19-1356}, booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, publisher={Association for Computational Linguistics}, author={Jawahar, Ganesh and Sagot, Benoît and Seddah, Djamé}, year={2019}, pages={36513657} }

